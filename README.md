# LangChain-Models

A collection of example code for working with **LLMs**, **Chat Models**, and **Embedding Models** from multiple providers â€” both **open-source** and **closed-source** â€” using [LangChain](https://www.langchain.com/) and the **Hugging Face API**.  

This repo demonstrates how to integrate, test, and run models like **OpenAI GPT**, **Google Gemini**, and **various Hugging Face models** in a unified workflow.

---

## âœ¨ Features

- **LLMs**: Examples of text generation using multiple providers.
- **Chat Models**: Conversational AI examples with context management.
- **Embedding Models**: Create vector embeddings for search, similarity, and RAG.
- **Multi-provider setup**:  
  - **Closed-source**: OpenAI, Gemini  
  - **Open-source**: Hugging Face Hub models
- **Environment variable management** with `.env`  
- **Practical LangChain usage** for different model types.

---

## ðŸ“‚ Project Structure

```plaintext
LangChain-Models/
â”‚
â”œâ”€â”€ LLMs/                 # Code examples for language models
â”œâ”€â”€ ChatModels/           # Code examples for conversational models
â”œâ”€â”€ Embeddings/           # Code examples for embedding models
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .env.example          # Example environment variable file
â””â”€â”€ README.md             # This file

---

## âš¡ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/dayanatif/LangChain-Models.git
   cd LangChain-Models

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt

